基于Llama

[BloombergGPT论文简介_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1Dg4y1u7fh/?spm_id_from=333.999.0.0&vd_source=51c3e05edfa923bc859a70d024c2d7c9)
这里面提到了wordpiece，训练的时候用这个model才能多语言比较好

[ChatGLM微调经验分享（基于lora）_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1eL41127uC/?-Arouter=story&buvid=Z04E510301E2317E4258B86E9DE3EE9C4D01&is_story_h5=false&mid=VWzcmGUtEsG3cu5l2eCFlg%3D%3D&p=1&plat_id=163&share_from=ugc&share_medium=iphone&share_plat=ios&share_session_id=BD109E67-D22A-4874-837A-F22D6DA7CF3D&share_source=WEIXIN&share_tag=s_i&timestamp=1681072448&unique_k=iyYnae6&up_id=7990701)

[mymusise/ChatGLM-Tuning: 一种平价的chatgpt实现方案, 基于ChatGLM-6B + LoRA (github.com)](https://github.com/mymusise/ChatGLM-Tuning)

[清华大学公布了1300亿参数的新模型，可以在在线随便试_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1oF411A744/?spm_id_from=333.788.recommend_more_video.1&vd_source=51c3e05edfa923bc859a70d024c2d7c9)
[THUDM/ChatGLM-6B: ChatGLM-6B: An Open Bilingual Dialogue Language Model | 开源双语对话语言模型 (github.com)](https://github.com/THUDM/ChatGLM-6B)
