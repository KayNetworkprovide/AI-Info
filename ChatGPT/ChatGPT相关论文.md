
 

**Papers论文清单**

1.【GPT-1】Improving Language Understanding by Generative Pre-Training.

PDF下载地址

[https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf)

2.【GPT-2】Language Models are Unsupervised Multitask Learners.

PDF下载地址

[https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)

3.【GPT-3】Language Models are Few-Shot Learners.

PDF下载地址

[https://arxiv.org/abs/2005.14165](https://arxiv.org/abs/2005.14165)

4.【InstructGPT】Training language models to follow instructions with human feedback.

PDF下载地址

[https://arxiv.org/pdf/2203.02155.pdf](https://arxiv.org/pdf/2203.02155.pdf)

5.【RLHF】Augmenting Reinforcement Learning with Human Feedback.

PDF下载地址

[https://www.cs.utexas.edu/~ai-lab/pubs/ICML_IL11-knox.pdf](https://www.cs.utexas.edu/~ai-lab/pubs/ICML_IL11-knox.pdf)

6.【PPO】Proximal Policy Optimization Algorithms.

PDF下载地址

[https://arxiv.org/abs/1707.06347](https://arxiv.org/abs/1707.06347)

7.【LaMda】 LaMDA: Language Models for Dialog Applications.

PDF下载地址

https://arxiv.org/abs/2201.08239

8.【Sparrow】 Improving alignment of dialogue agents via targeted human judgements.

PDF下载地址

[https://arxiv.org/abs/2209.14375](https://arxiv.org/abs/2209.14375)

9.【Claude】Constitutional AI: Harmlessness from AI Feedback.

PDF下载地址

[https://arxiv.org/abs/2212.08073](https://arxiv.org/abs/2212.08073)

10.OPT-IML: Scaling Language Model Instruction Meta Learning through the Lens of Generalization.

PDF下载地址

[https://arxiv.org/abs/2212.12017](https://arxiv.org/abs/2212.12017)

11.Fine-tuning language models from human preferences.

PDF下载地址

[https://arxiv.org/abs/1909.08593](https://arxiv.org/abs/1909.08593)

 

CODE下载地址

[https://github.com/openai/lm-human-preferences](https://github.com/openai/lm-human-preferences)

12.Learning to summarize from human feedback.

PDF下载地址

[https://arxiv.org/abs/2009.01325](https://arxiv.org/abs/2009.01325)

 

CODE下载地址

[https://github.com/openai/summarize-from-feedback](https://github.com/openai/summarize-from-feedback)

13.Cross-task generalization via natural language crowdsourcing instructions.

PDF下载地址

[https://aclanthology.org/2022.acl-long.244/](https://aclanthology.org/2022.acl-long.244/)

14.Finetuned language models are zero-shot learners

CODE下载地址

[https://arxiv.org/abs/2109.01652](https://arxiv.org/abs/2109.01652)

15.Multitask Prompted Training Enables Zero-Shot Task Generalization.

PDF下载地址

[https://arxiv.org/abs/2110.08207](https://arxiv.org/abs/2110.08207)

16.Super-NaturalInstructions: Generalization via Declarative Instructions on 1600+ NLP Tasks.

PDF下载地址

[https://arxiv.org/abs/2204.07705](https://arxiv.org/abs/2204.07705)

17.Putting Humans in the Natural Language Processing Loop: A Survey.

PDF下载地址

[https://aclanthology.org/2021.hcinlp-1.8.pdf](https://aclanthology.org/2021.hcinlp-1.8.pdf)

18.Scaling Instruction-Finetuned Language Models.

PDF下载地址

[https://arxiv.org/abs/2210.11416](https://arxiv.org/abs/2210.11416)

19.A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity.

PDF下载地址

[https://arxiv.org/abs/2302.04023](https://arxiv.org/abs/2302.04023)

20.Is ChatGPT a General-Purpose Natural Language Processing Task Solver?

PDF下载地址

[https://arxiv.org/abs/2302.06476](https://arxiv.org/abs/2302.06476)

21.The Wisdom of Hindsight Makes Language Models Better Instruction Followers.

PDF下载地址

[https://arxiv.org/abs/2302.05206](https://arxiv.org/abs/2302.05206)

[# 论文分享：新型注意力算法FlashAttention](https://www.bilibili.com/video/BV1zs4y1J7tb/?-Arouter=story&buvid=Z04E510301E2317E4258B86E9DE3EE9C4D01&is_story_h5=false&mid=VWzcmGUtEsG3cu5l2eCFlg%3D%3D&p=1&plat_id=163&share_from=ugc&share_medium=iphone&share_plat=ios&share_session_id=155A0611-EB32-4B6C-AD0D-CFAC1319AF7F&share_source=WEIXIN&share_tag=s_i&timestamp=1681395672&unique_k=Z176P67&up_id=1540261574)
